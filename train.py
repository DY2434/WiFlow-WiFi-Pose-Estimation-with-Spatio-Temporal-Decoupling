import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import math
import os
import copy
import pandas as pd
import cv2
from tqdm import tqdm
import traceback # ç”¨äºé”™è¯¯æŠ¥å‘Š
from torch.cuda.amp import GradScaler, autocast
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
import warnings
from models.pose_model import WiFlowPoseModel
from losses.pose_loss import PoseLoss
from utils.metrics import calculate_pck, calculate_mpjpe
from visualization import create_side_by_side_video_opencv, save_all_predictions, calculate_keypoint_errors

def get_gpu_memory_map():
    """è·å–æ‰€æœ‰GPUçš„æ˜¾å­˜ä¿¡æ¯"""
    result = {}
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024 ** 3
            result[i] = gpu_memory
    return result

def calculate_optimal_batch_size(gpu_id):
    """æ ¹æ®GPUæ˜¾å­˜è®¡ç®—æœ€ä¼˜æ‰¹é‡å¤§å°"""
    if not torch.cuda.is_available():
        return 32

    gpu_memory = torch.cuda.get_device_properties(gpu_id).total_memory / 1024 ** 3

    if gpu_memory > 40:
        return 64
    elif gpu_memory > 20:
        return 64
    elif gpu_memory > 10:
        return 128
    else:
        return 128

def train_pose_model(train_loader, val_loader, test_loader,
                     batch_size=32, n_epochs=100, patience=5,
                     lr=1e-4, weight_decay=1e-5, keypoint_scale=1000.0,
                     gpu_config='auto', output_dir="vis_results", use_augmentation=False):
    """ä½¿ç”¨ç®€åŒ–æŸå¤±å‡½æ•°çš„è®­ç»ƒå‡½æ•°"""
    os.makedirs(output_dir, exist_ok=True)

    # GPUé…ç½®
    if gpu_config == 'auto':
        gpu_memory_map = get_gpu_memory_map()
        rtx4090_ids = [i for i, mem in gpu_memory_map.items() if mem > 40]
        if rtx4090_ids:
            gpu_ids = rtx4090_ids[:1]
            print(f"è‡ªåŠ¨é€‰æ‹©: ä½¿ç”¨RTX 4090 (GPU {gpu_ids[0]})")
        else:
            gpu_ids = list(range(torch.cuda.device_count()))
            print(f"è‡ªåŠ¨é€‰æ‹©: ä½¿ç”¨æ‰€æœ‰GPU {gpu_ids}")
    else:
        gpu_ids = [int(x) for x in gpu_config.split(',')]

    print(f"ä½¿ç”¨GPU: {gpu_ids}")
    print(f"æ•°æ®å¢å¼º: {'å¯ç”¨' if use_augmentation else 'ç¦ç”¨'}")
    device = torch.device(f"cuda:{gpu_ids[0]}" if torch.cuda.is_available() else "cpu")

    # æ‰¹é‡å¤§å°é…ç½®
    if torch.cuda.is_available():
        gpu_batch_sizes = [calculate_optimal_batch_size(gpu_id) for gpu_id in gpu_ids]
        physical_batch_size = min(gpu_batch_sizes)
        if len(gpu_ids) == 1 and gpu_ids[0] == 1:
            physical_batch_size = 64
    else:
        physical_batch_size = 64

    gradient_accumulation_steps = max(1, batch_size // (physical_batch_size * len(gpu_ids)))
    effective_batch_size = physical_batch_size * len(gpu_ids) * gradient_accumulation_steps

    print(f"æ‰¹é‡é…ç½®: ç‰©ç†æ‰¹é‡={physical_batch_size}, GPUæ•°é‡={len(gpu_ids)}, "
          f"æ¢¯åº¦ç´¯ç§¯={gradient_accumulation_steps}, æœ‰æ•ˆæ‰¹é‡={effective_batch_size}")

    # åˆå§‹åŒ–æ¨¡å‹
    model = WiFlowPoseModel(dropout=0.5).to(device)


    if len(gpu_ids) > 1:
        model = nn.DataParallel(model, device_ids=gpu_ids)
        print("ä½¿ç”¨DataParallel")

    # æ··åˆç²¾åº¦è®­ç»ƒ
    scaler = GradScaler()

    # ä½¿ç”¨æ–°çš„ç®€åŒ–æŸå¤±å‡½æ•°
    criterion = PoseLoss(
        position_weight=1.0,
        bone_weight=0.2,  # å¢åŠ éª¨éª¼é•¿åº¦æƒé‡
        loss_type='smooth_l1'
    )

    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=lr,
        weight_decay=5e-5,  # å¢åŠ æƒé‡è¡°å‡
        betas=(0.9, 0.999)
    )

    scheduler = ReduceLROnPlateau(
        optimizer,
        mode='min',
        factor=0.5,
        patience=3,
        # verbose=True,
        min_lr=lr / 1000,
        cooldown=1,
        threshold=1e-4
    )

    # ä¿å­˜è®­ç»ƒå†å² - ç§»é™¤æ—¶åºç›¸å…³çš„é¡¹
    history = {
        'train_loss': [], 'val_loss': [],
        'train_position_loss': [], 'train_bone_loss': [],
        'train_mpe': [], 'val_mpe': [],
        'train_pck': [], 'val_pck': [],
        'train_pck50': [], 'val_pck50': [],
        'lr': []
    }

    # æ—©åœå‚æ•°
    best_val_mpe = float('inf')  # MPEè¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥åˆå§‹åŒ–ä¸ºæ— ç©·å¤§
    patience_counter = 0
    best_model = None
    best_epoch = 0
    best_val_metrics = {'loss': float('inf'), 'mpe': float('inf'), 'pck': 0.0}

    # é‡æ–°åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = train_loader.dataset
    val_dataset = val_loader.dataset
    test_dataset = test_loader.dataset

    val_batch_size = physical_batch_size // 2

    train_loader_optimized = DataLoader(
        train_dataset,
        batch_size=physical_batch_size,
        shuffle=True,
        pin_memory=True,
        drop_last=True
    )

    val_loader_optimized = DataLoader(
        val_dataset,
        batch_size=val_batch_size,
        shuffle=False,
        pin_memory=True,
        drop_last=True
    )

    print(f"å¼€å§‹è®­ç»ƒï¼Œå…±{n_epochs}ä¸ªepoch...")

    for epoch in range(n_epochs):
        # ====== è®­ç»ƒé˜¶æ®µ ======
        model.train()

        train_total_loss = 0.0
        train_total_position_loss = 0.0
        train_total_bone_loss = 0.0
        train_total_mpe = 0.0
        train_total_pck = 0.0
        train_total_pck50 = 0.0
        train_samples = 0
        optimizer.zero_grad()

        train_loop = tqdm(train_loader_optimized, desc=f"Epoch {epoch + 1}/{n_epochs} [Train]")
        current_step = 0

        for batch_idx, (batch_x, batch_y) in enumerate(train_loop):
            try:
                batch_x = batch_x.to(device, non_blocking=True)
                batch_y = batch_y.to(device, non_blocking=True)

                # å¢å¼ºçš„æ•°æ®å¢å¼º
                if use_augmentation and epoch > 0:
                    if torch.rand(1).item() < 0.6:
                        batch_x = time_masking(batch_x.permute(0, 2, 1), mask_ratio=0.3).permute(0, 2, 1)
                    if torch.rand(1).item() < 0.6:
                        batch_x = add_noise(batch_x, noise_level=0.02)
                    if torch.rand(1).item() < 0.5:
                        batch_x = random_scaling(batch_x, scale_range=(0.9, 1.1))

                # ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
                with autocast():
                    outputs = model(batch_x)
                    loss, loss_dict = criterion(outputs, batch_y)
                    loss = loss / gradient_accumulation_steps

                # åå‘ä¼ æ’­
                scaler.scale(loss).backward()

                # è®¡ç®—æŒ‡æ ‡
                with torch.no_grad():
                    mpe = calculate_mpjpe(outputs.detach(), batch_y)
                    pck_results = calculate_pck(outputs.detach(), batch_y, thresholds=[0.2, 0.5])
                    pck = pck_results[0.2]
                    pck50 = pck_results[0.5]

                # ç´¯ç§¯ç»Ÿè®¡ä¿¡æ¯
                current_batch_size = batch_y.size(0)
                train_total_loss += (loss.item() * gradient_accumulation_steps) * current_batch_size
                train_total_position_loss += loss_dict['position'] * current_batch_size
                train_total_bone_loss += loss_dict['bone'] * current_batch_size
                train_total_mpe += mpe * current_batch_size
                train_total_pck += pck * current_batch_size
                train_total_pck50 += pck50 * current_batch_size
                train_samples += current_batch_size

                # æ›´æ–°è¿›åº¦æ¡
                cur_loss = loss.item() * gradient_accumulation_steps
                train_loop.set_postfix(
                    loss=f"{cur_loss:.4f}",
                    mpe=f"{mpe:.4f}",
                    pck20=f"{pck:.4f}",
                    pck50=f"{pck50:.4f}",
                    lr=f"{optimizer.param_groups[0]['lr']:.6f}"
                )

                # æ¢¯åº¦ç´¯ç§¯
                current_step += 1
                if current_step >= gradient_accumulation_steps:
                    scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                    scaler.step(optimizer)
                    scaler.update()
                    optimizer.zero_grad()
                    current_step = 0

                # å†…å­˜æ¸…ç†
                if batch_idx % 100 == 0 and torch.cuda.is_available():
                    torch.cuda.empty_cache()

            except RuntimeError as e:
                if "size of tensor a" in str(e) and "must match the size of tensor b" in str(e):
                    print(f"æ‰¹æ¬¡ {batch_idx}: å¼ é‡å¤§å°ä¸åŒ¹é…ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
                    continue
                else:
                    print(f"è®­ç»ƒä¸­é‡åˆ°é”™è¯¯: {e}")
                    torch.cuda.empty_cache()
                    continue

        # å¤„ç†æœ€åä¸€ä¸ªä¸å®Œæ•´çš„ç´¯ç§¯æ‰¹æ¬¡
        if current_step > 0:
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            optimizer.zero_grad()
            scaler.update()

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        if train_samples > 0:
            train_loss = train_total_loss / train_samples
            train_position_loss = train_total_position_loss / train_samples
            train_bone_loss = train_total_bone_loss / train_samples
            train_mpe = train_total_mpe / train_samples
            train_pck = train_total_pck / train_samples
            train_pck50 = train_total_pck50 / train_samples
        else:
            train_loss = float('inf')
            train_position_loss = train_bone_loss = float('inf')
            train_mpe = float('inf')
            train_pck = train_pck50 = 0.0

        # ====== éªŒè¯é˜¶æ®µ ======
        torch.cuda.empty_cache()
        model.eval()

        val_total_loss = 0.0
        val_total_mpe = 0.0
        val_total_pck = 0.0
        val_total_pck50 = 0.0
        val_samples = 0

        val_loop = tqdm(val_loader_optimized, desc=f"Epoch {epoch + 1}/{n_epochs} [Val]")

        with torch.no_grad():
            for batch_idx, (batch_x, batch_y) in enumerate(val_loop):
                try:
                    batch_x = batch_x.to(device, non_blocking=True)
                    batch_y = batch_y.to(device, non_blocking=True)

                    outputs = model(batch_x)
                    loss, loss_dict = criterion(outputs, batch_y)

                    mpe = calculate_mpjpe(outputs, batch_y)
                    pck_results = calculate_pck(outputs, batch_y, thresholds=[0.2, 0.5])
                    pck = pck_results[0.2]
                    pck50 = pck_results[0.5]

                    current_batch_size = batch_y.size(0)
                    val_total_loss += loss.item() * current_batch_size
                    val_total_mpe += mpe * current_batch_size
                    val_total_pck += pck * current_batch_size
                    val_total_pck50 += pck50 * current_batch_size
                    val_samples += current_batch_size

                    val_loop.set_postfix(
                        loss=f"{loss.item():.4f}",
                        mpe=f"{mpe:.4f}",
                        pck20=f"{pck:.4f}",
                        pck50=f"{pck50:.4f}"
                    )

                except RuntimeError as e:
                    if "size of tensor a" in str(e) and "must match the size of tensor b" in str(e):
                        print(f"éªŒè¯æ‰¹æ¬¡ {batch_idx}: å¼ é‡å¤§å°ä¸åŒ¹é…ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
                        continue
                    else:
                        print(f"éªŒè¯å‡ºé”™: {e}")
                        torch.cuda.empty_cache()
                        continue

        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        if val_samples > 0:
            val_loss = val_total_loss / val_samples
            val_mpe = val_total_mpe / val_samples
            val_pck = val_total_pck / val_samples
            val_pck50 = val_total_pck50 / val_samples
        else:
            val_loss = float('inf')
            val_mpe = float('inf')
            val_pck = val_pck50 = 0.0

        # è®°å½•å†å²
        history['train_loss'].append(train_loss)
        history['val_loss'].append(val_loss)
        history['train_position_loss'].append(train_position_loss)
        history['train_bone_loss'].append(train_bone_loss)
        history['train_mpe'].append(train_mpe)
        history['val_mpe'].append(val_mpe)
        history['train_pck'].append(train_pck)
        history['val_pck'].append(val_pck)
        history['train_pck50'].append(train_pck50)
        history['val_pck50'].append(val_pck50)
        history['lr'].append(optimizer.param_groups[0]['lr'])

        # æ‰“å°è¯¦ç»†çš„æŸå¤±ä¿¡æ¯
        print(f"Epoch {epoch + 1}/{n_epochs}")
        print(f"  Train - Total: {train_loss:.4f}, Position: {train_position_loss:.4f}, "
              f"Bone: {train_bone_loss:.4f}")
        print(f"  Train - MPE: {train_mpe:.4f}, PCK@0.2: {train_pck:.4f}, PCK@0.5: {train_pck50:.4f}")
        print(f"  Val - Loss: {val_loss:.4f}, MPE: {val_mpe:.4f}, PCK@0.2: {val_pck:.4f}, PCK@0.5: {val_pck50:.4f}")
        print(f"  LR: {optimizer.param_groups[0]['lr']:.6f}")

        # åŸºäºéªŒè¯æŸå¤±è°ƒæ•´å­¦ä¹ ç‡
        scheduler.step(val_mpe)

        # æ—©åœæ£€æŸ¥
        if val_mpe < best_val_mpe:  # MPEè¶Šå°è¶Šå¥½
            best_val_mpe = val_mpe
            best_val_metrics['pck'] = val_pck
            best_val_metrics['mpe'] = val_mpe
            best_val_metrics['loss'] = val_loss

            if hasattr(model, 'module'):
                best_model = copy.deepcopy(model.module.state_dict())
            else:
                best_model = copy.deepcopy(model.state_dict())

            best_epoch = epoch
            patience_counter = 0

            model_path = os.path.join(output_dir, "best_pose_model.pth")
            torch.save(best_model, model_path)
            print(f"  ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {best_epoch + 1}, MPE={val_mpe:.4f}) åˆ° {model_path}")
        else:
            patience_counter += 1
            print(f"  éªŒè¯MPEæœªæ”¹å–„ï¼Œè€å¿ƒè®¡æ•°: {patience_counter}/{patience}")

        if patience_counter >= patience:
            print(f"â¹ï¸ æ—©åœåœ¨ {epoch + 1} ä¸ªepochåè§¦å‘ã€‚æœ€ä½³epoch: {best_epoch + 1}")
            break

    # åŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæµ‹è¯•
    if best_model is not None:
        if hasattr(model, 'module'):
            model.module.load_state_dict(best_model)
        else:
            model.load_state_dict(best_model)
        print(f"âœ… åŠ è½½æœ€ä½³æ¨¡å‹ï¼Œæ¥è‡ª epoch {best_epoch + 1}")

    print(f"ğŸ¯ æœ€ä½³éªŒè¯æŒ‡æ ‡ - Loss: {best_val_metrics['loss']:.4f}, "
          f"MPE: {best_val_metrics['mpe']:.4f}, PCK@0.2: {best_val_metrics['pck']:.4f}")

    # ä¿å­˜è®­ç»ƒå†å²å›¾è¡¨
    print("ğŸ“Š æ­£åœ¨ç”Ÿæˆè®­ç»ƒå†å²æ›²çº¿å›¾...")
    plot_training_history(history, output_dir)

    # ====== æµ‹è¯•é˜¶æ®µ ======
    test_loader_optimized = DataLoader(
        test_dataset,
        batch_size=val_batch_size,
        shuffle=False,
        pin_memory=True,
        drop_last=True
    )

    model.eval()

    test_total_loss = 0.0
    test_total_mpe = 0.0
    test_total_pck10 = 0.0
    test_total_pck20 = 0.0
    test_total_pck30 = 0.0
    test_total_pck40 = 0.0
    test_total_pck50 = 0.0
    test_samples = 0
    all_pred_keypoints = []
    all_true_keypoints = []

    test_loop = tqdm(test_loader_optimized, desc="æµ‹è¯•ä¸­")

    with torch.no_grad():
        for batch_idx, (batch_x, batch_y) in enumerate(test_loop):
            try:
                batch_x = batch_x.to(device, non_blocking=True)
                batch_y = batch_y.to(device, non_blocking=True)

                outputs = model(batch_x)
                loss, _ = criterion(outputs, batch_y)

                mpe = calculate_mpjpe(outputs, batch_y)
                pck_results = calculate_pck(outputs, batch_y, thresholds=[0.1, 0.2, 0.3, 0.4, 0.5])
                pck10 = pck_results[0.1]
                pck20 = pck_results[0.2]
                pck30 = pck_results[0.3]
                pck40 = pck_results[0.4]
                pck50 = pck_results[0.5]

                current_batch_size = batch_y.size(0)
                test_total_loss += loss.item() * current_batch_size
                test_total_mpe += mpe * current_batch_size
                test_total_pck10 += pck10 * current_batch_size
                test_total_pck20 += pck20 * current_batch_size
                test_total_pck30 += pck30 * current_batch_size
                test_total_pck40 += pck40 * current_batch_size
                test_total_pck50 += pck50 * current_batch_size
                test_samples += current_batch_size

                all_pred_keypoints.append(outputs.cpu().numpy())
                all_true_keypoints.append(batch_y.cpu().numpy())

                test_loop.set_postfix(
                    loss=f"{loss.item():.4f}",
                    mpe=f"{mpe:.4f}",
                    pck20=f"{pck20:.4f}",
                    pck50=f"{pck50:.4f}"
                )

            except RuntimeError as e:
                if "size of tensor a" in str(e) and "must match the size of tensor b" in str(e):
                    print(f"æµ‹è¯•æ‰¹æ¬¡ {batch_idx}: å¼ é‡å¤§å°ä¸åŒ¹é…ï¼Œè·³è¿‡è¯¥æ‰¹æ¬¡")
                    continue
                else:
                    print(f"æµ‹è¯•æ—¶å‡ºé”™: {e}")
                    torch.cuda.empty_cache()
                    continue

    # è®¡ç®—æµ‹è¯•æŒ‡æ ‡
    if test_samples > 0:
        test_loss = test_total_loss / test_samples
        test_mpe = test_total_mpe / test_samples
        test_pck10 = test_total_pck10 / test_samples
        test_pck20 = test_total_pck20 / test_samples
        test_pck30 = test_total_pck30 / test_samples
        test_pck40 = test_total_pck40 / test_samples
        test_pck50 = test_total_pck50 / test_samples
    else:
        test_loss = float('inf')
        test_mpe = float('inf')
        test_pck10 = test_pck20 = test_pck30 = test_pck40 = test_pck50 = 0.0

    # æ˜¾ç¤ºæ‰€æœ‰PCKé˜ˆå€¼çš„æµ‹è¯•ç»“æœ
    print(f"ğŸ¯ æµ‹è¯•ç»“æœ:")
    print(f"   Loss: {test_loss:.4f}")
    print(f"   MPE: {test_mpe:.4f}")
    print(f"   PCK@0.1: {test_pck10:.4f}")
    print(f"   PCK@0.2: {test_pck20:.4f}")
    print(f"   PCK@0.3: {test_pck30:.4f}")
    print(f"   PCK@0.4: {test_pck40:.4f}")
    print(f"   PCK@0.5: {test_pck50:.4f}")

    # ä¿å­˜é¢„æµ‹ç»“æœå’Œç”Ÿæˆè§†é¢‘
    if all_pred_keypoints and all_true_keypoints:
        all_preds = np.vstack(all_pred_keypoints)
        all_trues = np.vstack(all_true_keypoints)

        # ä¿å­˜é¢„æµ‹ç»“æœ
        predictions_file = os.path.join(output_dir, "test_predictions.csv")
        save_all_predictions(all_trues, all_preds, predictions_file, keypoint_scale)
        print(f"ğŸ’¾ å·²ä¿å­˜æµ‹è¯•é¢„æµ‹ç»“æœåˆ°: {predictions_file}")

        # è®¡ç®—å…³é”®ç‚¹è¯¯å·®ç»Ÿè®¡
        error_stats = calculate_keypoint_errors(
            all_trues[:min(1000, len(all_trues))],
            all_preds[:min(1000, len(all_preds))],
            keypoint_scale=keypoint_scale
        )
        error_stats_file = os.path.join(output_dir, "keypoint_error_stats.csv")
        error_stats.to_csv(error_stats_file)
        print(f"ğŸ“Š å·²ä¿å­˜å…³é”®ç‚¹è¯¯å·®ç»Ÿè®¡åˆ°: {error_stats_file}")

        # ä¿å­˜è¯¦ç»†çš„æµ‹è¯•ç»“æœåˆ°CSV
        test_results_file = os.path.join(output_dir, "test_results_summary.csv")
        test_results_data = {
            'Metric': ['Loss', 'MPE', 'PCK@0.1', 'PCK@0.2', 'PCK@0.3', 'PCK@0.4', 'PCK@0.5'],
            'Value': [test_loss, test_mpe, test_pck10, test_pck20, test_pck30, test_pck40, test_pck50]
        }
        import pandas as pd
        test_results_df = pd.DataFrame(test_results_data)
        test_results_df.to_csv(test_results_file, index=False)
        print(f"ğŸ“Š å·²ä¿å­˜æµ‹è¯•ç»“æœæ±‡æ€»åˆ°: {test_results_file}")

        # ç”Ÿæˆè§†é¢‘
        try:
            videos_dir = os.path.join(output_dir, "videos")
            os.makedirs(videos_dir, exist_ok=True)

            frames_to_animate = min(720, len(all_preds))
            print(f"æ­£åœ¨ä¸ºå‰{frames_to_animate}å¸§ç”Ÿæˆè§†é¢‘...")

            # 1. åˆ›å»ºçœŸå®å§¿æ€è§†é¢‘
            print("æ­£åœ¨ç”ŸæˆçœŸå®å§¿æ€è§†é¢‘...")
            true_subset = all_trues[:frames_to_animate].copy()
            true_animation = create_pose_animation_opencv(
                true_subset,
                output_file=os.path.join(videos_dir, "true_poses.mp4"),
                keypoint_scale=keypoint_scale,
                show_labels=True
            )
            print(f"å·²ç”ŸæˆçœŸå®å§¿æ€è§†é¢‘: {true_animation}")

            # 2. åˆ›å»ºé¢„æµ‹å§¿æ€è§†é¢‘
            print("æ­£åœ¨ç”Ÿæˆé¢„æµ‹å§¿æ€è§†é¢‘...")
            pred_subset = all_preds[:frames_to_animate].copy()
            pred_animation = create_pose_animation_opencv(
                pred_subset,
                output_file=os.path.join(videos_dir, "predicted_poses.mp4"),
                keypoint_scale=keypoint_scale,
                show_labels=True
            )
            print(f"å·²ç”Ÿæˆé¢„æµ‹å§¿æ€è§†é¢‘: {pred_animation}")

            # 3. åˆ›å»ºå¯¹æ¯”è§†é¢‘
            print("æ­£åœ¨ç”Ÿæˆå¯¹æ¯”è§†é¢‘...")
            comparison_video = create_side_by_side_video_opencv(
                true_subset,
                pred_subset,
                output_file=os.path.join(videos_dir, "comparison_poses.mp4"),
                keypoint_scale=keypoint_scale,
                fps=30
            )
            print(f"å·²ç”Ÿæˆå¯¹æ¯”è§†é¢‘: {comparison_video}")

            print(f"å·²å®Œæˆæ‰€æœ‰è§†é¢‘çš„ç”Ÿæˆï¼Œä¿å­˜åœ¨ {videos_dir} ç›®å½•ä¸‹")

        except Exception as e:
            print(f"ç”Ÿæˆè§†é¢‘æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    return model, history, test_loss, test_pck20, test_mpe, {
        'pck10': test_pck10,
        'pck20': test_pck20,
        'pck30': test_pck30,
        'pck40': test_pck40,
        'pck50': test_pck50
    }