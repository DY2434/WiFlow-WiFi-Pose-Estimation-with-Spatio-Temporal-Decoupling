import scipy.io as sio
from torch.utils.data import TensorDataset, DataLoader
import numpy as np
import torch
import torch.nn as nn
from torch.autograd import Variable
import torch.nn.functional as F
import math
import time
import sys
import glob
import hdf5storage
from random import shuffle
import time
import os
import pandas as pd
from torch.utils.data import Dataset, DataLoader
import copy
from tqdm import tqdm
import matplotlib.pyplot as plt
import cv2
from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas

# ============================== #
# æ•°æ®åŠ è½½å’Œè½¬æ¢ç›¸å…³ä»£ç ï¼ˆä¿®æ”¹ä¸ºæ”¯æŒPAMæ ¼å¼ï¼‰
# ============================== #

KEEP_KEYPOINTS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
KEYPOINT_MAPPING = {old_idx: new_idx for new_idx, old_idx in enumerate(KEEP_KEYPOINTS)}


class PreprocessedCSIKeypointsDataset(Dataset):
    """ä½¿ç”¨é¢„å¤„ç†åçš„CSIæ•°æ®å’ŒPAMæ ¼å¼æ ‡ç­¾çš„æ•°æ®é›†ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""

    def __init__(self, csi_data_dir, pam_label_dir, keypoint_scale=1000.0, transform=None, enable_zero_clean=True):
        self.csi_windows = np.load(os.path.join(csi_data_dir, "csi_windows.npy"))

        window_info = np.load(os.path.join(csi_data_dir, "window_info.npz"))
        self.window_to_file = window_info['window_to_file']
        self.window_to_frame = window_info['window_to_frame']

        file_info = np.load(os.path.join(csi_data_dir, "file_info.npz"), allow_pickle=True)
        self.file_ids = file_info['file_ids']
        self.window_ranges = file_info['window_ranges']

        config = np.load(os.path.join(csi_data_dir, "config.npz"))
        self.window_size = config['window_size']
        self.stride = config['stride']

        self.keypoint_scale = keypoint_scale
        self.transform = transform
        self.pam_label_dir = pam_label_dir
        self.enable_zero_clean = enable_zero_clean

        # ç¼“å­˜å•ä¸ªPAMå¸§ï¼ˆè€Œä¸æ˜¯æ•´ä¸ªåºåˆ—ï¼‰
        self._pam_cache = {}
        self._cache_size = 100  # å¢åŠ ç¼“å­˜å¤§å°

        print(f"åŠ è½½äº† {len(self.csi_windows)} ä¸ªCSIçª—å£")
        print(f"PAMæ ‡ç­¾ç›®å½•: {pam_label_dir}")
        print(f"æ–‡ä»¶IDæ•°é‡: {len(self.file_ids)}")
        print(f"é›¶å€¼æ¸…ç†: {'å¯ç”¨(å•å¸§å‡å€¼æ³•)' if enable_zero_clean else 'ç¦ç”¨'}")

    def _get_pam_file_path(self, file_idx, frame_idx):
        """æ ¹æ®æ–‡ä»¶ç´¢å¼•å’Œå¸§ç´¢å¼•è·å–PAMæ–‡ä»¶è·¯å¾„"""
        file_id = self.file_ids[file_idx]
        pam_filename = f"{file_id}_dual_cropped_frame_{frame_idx:06d}.mat"

        for person_idx in range(1, 6):
            person_dir = os.path.join(self.pam_label_dir, f"wisppn_labels{person_idx}")
            pam_path = os.path.join(person_dir, pam_filename)
            if os.path.exists(pam_path):
                return pam_path
        return None

    def _clean_single_frame_zeros(self, keypoint):
        """æ¸…ç†å•å¸§ä¸­çš„é›¶å€¼å…³é”®ç‚¹ï¼ˆå•å¸§å‡å€¼æ³•ï¼‰"""
        cleaned = keypoint.copy()

        # æ‰¾åˆ°éé›¶å…³é”®ç‚¹çš„æ©ç 
        non_zero_mask = (keypoint[:, 0] != 0) | (keypoint[:, 1] != 0)

        # åªæœ‰å½“å­˜åœ¨è‡³å°‘ä¸€ä¸ªéé›¶ç‚¹æ—¶æ‰è¿›è¡Œå¤„ç†
        if non_zero_mask.any():
            # è®¡ç®—éé›¶å…³é”®ç‚¹çš„å¹³å‡ä½ç½®
            mean_pos = keypoint[non_zero_mask].mean(axis=0)
            # æ‰¾åˆ°æ‰€æœ‰é›¶å€¼ç‚¹çš„ç´¢å¼•
            zero_indices = np.where(~non_zero_mask)[0]

            # ç”¨å‡å€¼æ›¿æ¢é›¶å€¼ç‚¹
            for idx in zero_indices:
                cleaned[idx] = mean_pos

        return cleaned

    def _load_pam_frame(self, file_idx, frame_idx):
        """åŠ è½½ç‰¹å®šå¸§çš„PAMæ•°æ®ï¼ˆæŒ‰éœ€åŠ è½½ï¼‰"""
        cache_key = f"{file_idx}_{frame_idx}"

        if cache_key in self._pam_cache:
            return self._pam_cache[cache_key]

        # ç¼“å­˜ç®¡ç† - LRUç­–ç•¥
        if len(self._pam_cache) >= self._cache_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
            oldest_key = next(iter(self._pam_cache))
            del self._pam_cache[oldest_key]

        # è·å–PAMæ–‡ä»¶è·¯å¾„
        pam_path = self._get_pam_file_path(file_idx, frame_idx)

        if pam_path is None:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›é›¶çŸ©é˜µ
            pam_data = np.zeros((3, 15, 15), dtype=np.float32)
        else:
            try:
                # åŠ è½½.matæ–‡ä»¶
                data = hdf5storage.loadmat(pam_path)
                pam_data = data['jointsMatrix'][:3, :, :].astype(np.float32)

                # å¦‚æœå¯ç”¨æ¸…ç†ï¼Œåº”ç”¨å•å¸§å‡å€¼æ¸…ç†
                if self.enable_zero_clean:
                    # æå–å…³é”®ç‚¹åæ ‡
                    keypoints = np.zeros((15, 2), dtype=np.float32)
                    for kp_idx in range(15):
                        keypoints[kp_idx, 0] = pam_data[0, kp_idx, kp_idx]
                        keypoints[kp_idx, 1] = pam_data[1, kp_idx, kp_idx]

                    # æ¸…ç†é›¶å€¼
                    cleaned_keypoints = self._clean_single_frame_zeros(keypoints)

                    # æ›´æ–°PAMçŸ©é˜µ
                    for kp_idx in range(15):
                        # æ›´æ–°å¯¹è§’çº¿ï¼ˆç»å¯¹åæ ‡ï¼‰
                        pam_data[0, kp_idx, kp_idx] = cleaned_keypoints[kp_idx, 0]
                        pam_data[1, kp_idx, kp_idx] = cleaned_keypoints[kp_idx, 1]

                    # æ›´æ–°éå¯¹è§’çº¿ï¼ˆç›¸å¯¹åæ ‡ï¼‰
                    for i in range(15):
                        for j in range(15):
                            if i != j:
                                pam_data[0, i, j] = cleaned_keypoints[i, 0] - cleaned_keypoints[j, 0]
                                pam_data[1, i, j] = cleaned_keypoints[i, 1] - cleaned_keypoints[j, 1]

                # å½’ä¸€åŒ–åæ ‡
                pam_data[0:2, :, :] = pam_data[0:2, :, :] / self.keypoint_scale
                # ç½®ä¿¡åº¦ä¿æŒä¸å˜

            except Exception as e:
                print(f"åŠ è½½PAMæ–‡ä»¶å¤±è´¥ {pam_path}: {e}")
                pam_data = np.zeros((3, 15, 15), dtype=np.float32)

        # ç¼“å­˜ç»“æœ
        self._pam_cache[cache_key] = pam_data
        return pam_data

    def __len__(self):
        return len(self.csi_windows)

    def __getitem__(self, idx):
        # è·å–CSIçª—å£
        csi_window = self.csi_windows[idx]

        # è·å–å¯¹åº”çš„æ–‡ä»¶å’Œå¸§ç´¢å¼•
        file_idx = self.window_to_file[idx]
        frame_idx = self.window_to_frame[idx]

        # æŒ‰éœ€åŠ è½½å•ä¸ªPAMå¸§
        pam_label = self._load_pam_frame(file_idx, frame_idx)

        # è½¬æ¢ä¸ºå¼ é‡
        csi_tensor = torch.from_numpy(csi_window).float()
        pam_tensor = torch.from_numpy(pam_label).float()

        if self.transform:
            csi_tensor = self.transform(csi_tensor)

        return csi_tensor, pam_tensor

    def get_file_indices(self):
        """è·å–æ‰€æœ‰æ–‡ä»¶ç´¢å¼•"""
        return list(range(len(self.file_ids)))

    def get_samples_from_file(self, file_idx):
        """è·å–æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰æ ·æœ¬ç´¢å¼•"""
        start_idx, end_idx = self.window_ranges[file_idx]
        return list(range(start_idx, end_idx))

def create_train_val_test_loaders(dataset, batch_size=32, num_workers=0, random_seed=42):
    """æŒ‰æ–‡ä»¶çº§åˆ«åˆ’åˆ†é¢„å¤„ç†åçš„æ•°æ®é›†"""
    # è®¾ç½®éšæœºç§å­
    np.random.seed(random_seed)

    # è·å–æ‰€æœ‰æ–‡ä»¶ç´¢å¼•
    file_indices = dataset.get_file_indices()
    total_files = len(file_indices)

    # éšæœºæ‰“ä¹±æ–‡ä»¶é¡ºåº
    np.random.shuffle(file_indices)

    # æŒ‰æ¯”ä¾‹åˆ’åˆ†æ–‡ä»¶
    train_ratio, val_ratio = 0.7, 0.15
    train_split = int(np.floor(train_ratio * total_files))
    val_split = int(np.floor(val_ratio * total_files))

    # è·å–æ¯ä¸ªé›†åˆçš„æ–‡ä»¶ç´¢å¼•
    train_file_indices = file_indices[:train_split]
    val_file_indices = file_indices[train_split:train_split + val_split]
    test_file_indices = file_indices[train_split + val_split:]

    # è·å–æ¯ä¸ªé›†åˆçš„æ ·æœ¬ç´¢å¼•
    train_indices = []
    val_indices = []
    test_indices = []

    for file_idx in train_file_indices:
        train_indices.extend(dataset.get_samples_from_file(file_idx))

    for file_idx in val_file_indices:
        val_indices.extend(dataset.get_samples_from_file(file_idx))

    for file_idx in test_file_indices:
        test_indices.extend(dataset.get_samples_from_file(file_idx))

    print(f"è®­ç»ƒé›†: {len(train_indices)} æ ·æœ¬ (æ¥è‡ª {len(train_file_indices)} ä¸ªæ–‡ä»¶)")
    print(f"éªŒè¯é›†: {len(val_indices)} æ ·æœ¬ (æ¥è‡ª {len(val_file_indices)} ä¸ªæ–‡ä»¶)")
    print(f"æµ‹è¯•é›†: {len(test_indices)} æ ·æœ¬ (æ¥è‡ª {len(test_file_indices)} ä¸ªæ–‡ä»¶)")

    # åˆ›å»ºå­é›†
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)
    test_dataset = torch.utils.data.Subset(dataset, test_indices)

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        pin_memory=True,
        num_workers=num_workers,
        drop_last=True
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        pin_memory=True,
        num_workers=num_workers,
        drop_last=True
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        pin_memory=True,
        num_workers=num_workers,
        drop_last=True
    )

    return train_loader, val_loader, test_loader


# ============================== #
# CSIæ•°æ®æ ¼å¼è½¬æ¢å‡½æ•°
# ============================== #

def convert_csi_format(csi_data_code2):
    """
    å°†ä»£ç 2çš„CSIæ•°æ®æ ¼å¼è½¬æ¢ä¸ºä»£ç 1çš„æ ¼å¼
    è¾“å…¥: [batch_size, 540, 20]
    è¾“å‡º: [batch_size, 600, 3, 6]
    """
    batch_size = csi_data_code2.shape[0]

    # æ­¥éª¤1: åˆ†ç¦»ä¸¤ä¸ªæ¥æ”¶ç«¯
    csi_split = csi_data_code2.view(batch_size, 2, 270, 20)

    # æ­¥éª¤2: æ¯ä¸ªæ¥æ”¶ç«¯é‡å¡‘ä¸º (30å­è½½æ³¢, 3å‘é€å¤©çº¿, 3æ¥æ”¶å¤©çº¿)
    csi_reshaped = csi_split.view(batch_size, 2, 30, 3, 3, 20)

    # æ­¥éª¤3: è°ƒæ•´ç»´åº¦é¡ºåºï¼Œå°†æ—¶é—´ç»´åº¦ç§»åˆ°å‰é¢
    csi_reordered = csi_reshaped.permute(0, 1, 5, 2, 3, 4)

    # æ­¥éª¤4: åˆå¹¶æ—¶é—´å’Œå­è½½æ³¢ç»´åº¦ï¼ŒåŒæ—¶åˆå¹¶ä¸¤ä¸ªæ¥æ”¶ç«¯çš„æ¥æ”¶å¤©çº¿
    batch_size, num_receivers, time_steps, num_subcarriers, tx_antennas, rx_antennas = csi_reordered.shape

    # é‡å¡‘ä¸ºæœ€ç»ˆæ ¼å¼
    csi_final = csi_reordered.contiguous().view(
        batch_size,
        time_steps * num_subcarriers,  # 600 = 20 Ã— 30
        tx_antennas,  # 3
        num_receivers * rx_antennas  # 6 = 2 Ã— 3
    )

    return csi_final


# ============================== #
# ResNetæ¨¡å‹ï¼ˆä¿®æ”¹è¾“å‡ºä¸º2é€šé“çš„PAMï¼‰
# ============================== #

def conv3x3(in_channels, out_channels, stride=1):
    return nn.Conv2d(in_channels, out_channels, kernel_size=3,
                     stride=stride, padding=1, bias=False)


class ResidualBlock(nn.Module):
    expansion = 1

    def __init__(self, in_channels, out_channels, stride=1, downsample=None):
        super(ResidualBlock, self).__init__()
        self.conv1 = conv3x3(in_channels, out_channels, stride)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = conv3x3(out_channels, out_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)
        self.downsample = downsample

    def forward(self, x):
        residual = x
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        out = self.conv2(out)
        out = self.bn2(out)
        if self.downsample:
            residual = self.downsample(x)
        out += residual
        out = self.relu(out)
        return out


class ResNet(nn.Module):
    def __init__(self, block, layers, input_channels=600):
        super(ResNet, self).__init__()

        self.in_channels = input_channels
        self.conv1 = nn.Sequential(
            nn.Conv2d(self.in_channels, self.in_channels, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(self.in_channels),
            nn.ReLU(inplace=True),
        )

        self.layer1 = self.make_layer(block, self.in_channels, layers[0])
        self.layer2 = self.make_layer(block, 600, layers[1], 2)
        self.layer3 = self.make_layer(block, 1024, layers[2], 2)
        self.layer4 = self.make_layer(block, 1024, layers[3], 2)

        self.decode = nn.Sequential(
            nn.Conv2d(1024, 256, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 64, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 2, kernel_size=1, stride=1, padding=0, bias=False),  # è¾“å‡º2é€šé“(x', y')
        )

    def make_layer(self, block, out_channels, blocks, stride=1):
        downsample = None
        if (stride != 1) or (self.in_channels != out_channels * block.expansion):
            downsample = nn.Sequential(
                conv3x3(self.in_channels, out_channels * block.expansion, stride=stride),
                nn.BatchNorm2d(out_channels * block.expansion))
        layers = []
        layers.append(block(self.in_channels, out_channels, stride, downsample))
        self.in_channels = out_channels * block.expansion
        for i in range(1, blocks):
            layers.append(block(self.in_channels, out_channels))
        return nn.Sequential(*layers)

    def forward(self, x):
        # è¾“å…¥: [batch_size, 600, 3, 6]
        # ä¸Šé‡‡æ ·åˆ°å¯¹ç§°çš„åˆ†è¾¨ç‡
        x = F.interpolate(x, size=(120, 120), mode='bilinear', align_corners=False)

        x = self.conv1(x)
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.decode(x)
        # è¾“å‡º: [batch_size, 2, height, width]

        # æœ€ç»ˆè¾“å‡º: [batch_size, 2, 15, 15]
        return x


# ============================== #
# å…³é”®ç‚¹æå–å‡½æ•°ï¼ˆä»PAMå¯¹è§’çº¿æå–ï¼‰
# ============================== #

def extract_keypoints_from_pam(pam_data, num_keypoints=15):
    """
    ä»PAMçŸ©é˜µä¸­æå–å…³é”®ç‚¹åæ ‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
    è¾“å…¥: pam_data [batch_size, 2, 15, 15] - PAMçš„x'å’Œy'é€šé“
    è¾“å‡º: keypoints [batch_size, num_keypoints, 2] - æå–çš„å…³é”®ç‚¹åæ ‡
    """
    batch_size = pam_data.shape[0]

    # åˆå§‹åŒ–å…³é”®ç‚¹åæ ‡
    keypoints = torch.zeros(batch_size, num_keypoints, 2, device=pam_data.device)

    # ä»å¯¹è§’çº¿å…ƒç´ æå–åæ ‡
    for b in range(batch_size):
        for k in range(num_keypoints):
            keypoints[b, k, 0] = pam_data[b, 0, k, k]  # xåæ ‡ä»ç¬¬0ä¸ªé€šé“çš„å¯¹è§’çº¿
            keypoints[b, k, 1] = pam_data[b, 1, k, k]  # yåæ ‡ä»ç¬¬1ä¸ªé€šé“çš„å¯¹è§’çº¿

    return keypoints


# ============================== #
# è¯„ä¼°å‡½æ•°
# ============================== #

def mean_keypoint_error(pred, target, keypoint_scale=1000.0):
    """è®¡ç®—å¹³å‡å…³é”®ç‚¹è¯¯å·®"""
    # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
    if len(pred.shape) == 3 and pred.shape[1] == 2 and pred.shape[2] == 15:
        pred = pred.transpose(1, 2)
    if len(target.shape) == 3 and target.shape[1] == 2 and target.shape[2] == 15:
        target = target.transpose(1, 2)

    # è®¡ç®—æ¬§æ°è·ç¦»
    distances = torch.sqrt(torch.sum((pred - target) ** 2, dim=2))

    # è®¡ç®—å¹³å‡è¯¯å·®
    mpe = torch.mean(distances) * keypoint_scale

    return mpe.item()


def calculate_pck_metrics(pred_coords, true_coords, thresholds=[0.1, 0.2, 0.3, 0.4, 0.5]):
    """è®¡ç®—PCKæŒ‡æ ‡ - ä¿®æ­£ç‰ˆæœ¬"""
    batch_size = pred_coords.shape[0]

    # ä½¿ç”¨æ­£ç¡®çš„èº¯å¹²é•¿åº¦ä½œä¸ºå‚è€ƒï¼šNeck(1) to MidHip(8)
    NECK_IDX = 2  # å³è‚©
    MIDHIP_IDX = 12  # å·¦é«‹

    # è®¡ç®—èº¯å¹²é•¿åº¦ä½œä¸ºå½’ä¸€åŒ–å‚è€ƒ
    torso_length = torch.sqrt(
        torch.sum((true_coords[:, NECK_IDX] - true_coords[:, MIDHIP_IDX]) ** 2, dim=1)
    )
    torso_length = torch.clamp(torso_length, min=0.01)  # é¿å…é™¤é›¶

    # è®¡ç®—æ‰€æœ‰å…³é”®ç‚¹çš„æ¬§æ°è·ç¦»
    distances = torch.sqrt(torch.sum((pred_coords - true_coords) ** 2, dim=2))

    # å½’ä¸€åŒ–è·ç¦»ï¼ˆç›¸å¯¹äºèº¯å¹²é•¿åº¦ï¼‰
    normalized_distances = distances / torso_length.unsqueeze(1)

    pck_results = {}
    for threshold in thresholds:
        correct = (normalized_distances < threshold).float()
        pck = torch.mean(correct).item()
        pck_results[threshold] = pck

    return pck_results


# ============================== #
# å§¿æ€å¯è§†åŒ–ç›¸å…³è®¾ç½®
# ============================== #

SKELETON_CONNECTIONS = [
    (0, 1), (1, 8),
    (1, 2), (2, 3), (3, 4),
    (1, 5), (5, 6), (6, 7),
    (8, 9), (8, 12),
    (9, 10), (10, 11),
    (12, 13), (13, 14)
]

# å®šä¹‰å…³é”®ç‚¹çš„èº«ä½“éƒ¨ä½åç§°
KEYPOINT_NAMES = {
    0: "Nose",
    1: "Neck",
    2: "RShoulder",
    3: "RElbow",
    4: "RWrist",
    5: "LShoulder",
    6: "LElbow",
    7: "LWrist",
    8: "MidHip",
    9: "RHip",
    10: "RKnee",
    11: "RAnkle",
    12: "LHip",
    13: "LKnee",
    14: "LAnkle"
}
# ============================== #
# è§†é¢‘å¯è§†åŒ–å‡½æ•°
# ============================== #

# ============================== #
# å§¿æ€å¯è§†åŒ–ç›¸å…³è®¾ç½®
# ============================== #

# æ ¹æ®å›¾ç‰‡ä¸­çš„å…³é”®ç‚¹è¿æ¥å®šä¹‰éª¨æ¶è¿æ¥
SKELETON_CONNECTIONS = [
    # èº¯å¹²
    (0, 1), (1, 8),
    # å·¦è‡‚
    (1, 2), (2, 3), (3, 4),
    # å³è‡‚
    (1, 5), (5, 6), (6, 7),
    # ä¸‹åŠèº«
    (8, 9), (8, 12),
    # å·¦è…¿
    (9, 10), (10, 11),
    # å³è…¿
    (12, 13), (13, 14)
]

# å®šä¹‰å…³é”®ç‚¹çš„èº«ä½“éƒ¨ä½åç§° - ç®€åŒ–ä¸º15ä¸ªç‚¹
# å®šä¹‰å…³é”®ç‚¹çš„èº«ä½“éƒ¨ä½åç§°
KEYPOINT_NAMES = {
    0: "Nose",
    1: "Neck",
    2: "RShoulder",
    3: "RElbow",
    4: "RWrist",
    5: "LShoulder",
    6: "LElbow",
    7: "LWrist",
    8: "MidHip",
    9: "RHip",
    10: "RKnee",
    11: "RAnkle",
    12: "LHip",
    13: "LKnee",
    14: "LAnkle"
}

# å®šä¹‰èº«ä½“éƒ¨ä½é¢œè‰²
BODY_PART_COLORS = {
    'head': 'magenta',
    'torso': 'red',
    'right_arm': 'orange',  # å³è‡‚
    'left_arm': 'green',     # å·¦è‡‚
    'right_leg': 'blue',     # å³è…¿
    'left_leg': 'cyan'       # å·¦è…¿
}

# å°†å…³é”®ç‚¹åˆ†ç»„åˆ°ä¸åŒçš„èº«ä½“éƒ¨ä½ - ç®€åŒ–ä¸º15ä¸ªç‚¹
KEYPOINT_GROUPS = {
    'head': [0],
    'torso': [1, 8],
    'left_arm': [2, 3, 4],
    'right_arm': [5, 6, 7],
    'left_leg': [9, 10, 11],
    'right_leg': [12, 13, 14]
}

# ä¸ºæ¯ä¸ªè¿æ¥åˆ†é…é¢œè‰²
CONNECTION_COLORS = {
    # èº¯å¹²
    (0, 1): BODY_PART_COLORS['torso'],  # Nose to Neck
    (1, 8): BODY_PART_COLORS['torso'],  # Neck to MidHip

    # å³è‡‚ï¼ˆRå¼€å¤´çš„ï¼‰
    (1, 2): BODY_PART_COLORS['right_arm'],  # Neck to RShoulder
    (2, 3): BODY_PART_COLORS['right_arm'],  # RShoulder to RElbow
    (3, 4): BODY_PART_COLORS['right_arm'],  # RElbow to RWrist

    # å·¦è‡‚ï¼ˆLå¼€å¤´çš„ï¼‰
    (1, 5): BODY_PART_COLORS['left_arm'],  # Neck to LShoulder
    (5, 6): BODY_PART_COLORS['left_arm'],  # LShoulder to LElbow
    (6, 7): BODY_PART_COLORS['left_arm'],  # LElbow to LWrist

    # é«‹éƒ¨è¿æ¥
    (8, 9): BODY_PART_COLORS['right_leg'],  # MidHip to RHip
    (8, 12): BODY_PART_COLORS['left_leg'],  # MidHip to LHip

    # å³è…¿
    (9, 10): BODY_PART_COLORS['right_leg'],  # RHip to RKnee
    (10, 11): BODY_PART_COLORS['right_leg'],  # RKnee to RAnkle

    # å·¦è…¿
    (12, 13): BODY_PART_COLORS['left_leg'],  # LHip to LKnee
    (13, 14): BODY_PART_COLORS['left_leg']  # LKnee to LAnkle
}

def create_pose_animation_opencv(all_keypoints, output_file="pose_animation.mp4", fps=30,
                                 figsize=(800, 960), keypoint_scale=1.0,
                                 show_labels=True, show_legend=True):
    """ä½¿ç”¨OpenCVå’Œtqdmåˆ›å»ºäººä½“å§¿æ€åŠ¨ç”»"""
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib.lines import Line2D
    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
    from tqdm import tqdm

    width, height = figsize
    frames = len(all_keypoints)
    reshaped_keypoints = all_keypoints.reshape(frames, -1, 2)

    if keypoint_scale != 1.0:
        reshaped_keypoints *= keypoint_scale

    all_x = reshaped_keypoints[:, :, 0].flatten()
    all_y = reshaped_keypoints[:, :, 1].flatten()

    x_min, x_max = np.min(all_x), np.max(all_x)
    y_min, y_max = np.min(all_y), np.max(all_y)

    margin = 0.1
    x_margin = (x_max - x_min) * margin
    y_margin = (y_max - y_min) * margin

    # éª¨éª¼è¿æ¥å’Œé¢œè‰²
    SKELETON_CONNECTIONS = [
        (0, 1), (1, 8),
        (1, 2), (2, 3), (3, 4),
        (1, 5), (5, 6), (6, 7),
        (8, 9), (8, 12),
        (9, 10), (10, 11),
        (12, 13), (13, 14)
    ]

    BODY_PART_COLORS = {
        'head': 'magenta',
        'torso': 'red',
        'right_arm': 'orange',  # å³è‡‚
        'left_arm': 'green',  # å·¦è‡‚
        'right_leg': 'blue',  # å³è…¿
        'left_leg': 'cyan'  # å·¦è…¿
    }

    KEYPOINT_GROUPS = {
        'head': [0],
        'torso': [1, 8],
        'left_arm': [2, 3, 4],
        'right_arm': [5, 6, 7],
        'left_leg': [9, 10, 11],
        'right_leg': [12, 13, 14]
    }

    CONNECTION_COLORS = {
        # èº¯å¹²
        (0, 1): BODY_PART_COLORS['torso'],  # Nose to Neck
        (1, 8): BODY_PART_COLORS['torso'],  # Neck to MidHip

        # å³è‡‚ï¼ˆRå¼€å¤´çš„ï¼‰
        (1, 2): BODY_PART_COLORS['right_arm'],  # Neck to RShoulder
        (2, 3): BODY_PART_COLORS['right_arm'],  # RShoulder to RElbow
        (3, 4): BODY_PART_COLORS['right_arm'],  # RElbow to RWrist

        # å·¦è‡‚ï¼ˆLå¼€å¤´çš„ï¼‰
        (1, 5): BODY_PART_COLORS['left_arm'],  # Neck to LShoulder
        (5, 6): BODY_PART_COLORS['left_arm'],  # LShoulder to LElbow
        (6, 7): BODY_PART_COLORS['left_arm'],  # LElbow to LWrist

        # é«‹éƒ¨è¿æ¥
        (8, 9): BODY_PART_COLORS['right_leg'],  # MidHip to RHip
        (8, 12): BODY_PART_COLORS['left_leg'],  # MidHip to LHip

        # å³è…¿
        (9, 10): BODY_PART_COLORS['right_leg'],  # RHip to RKnee
        (10, 11): BODY_PART_COLORS['right_leg'],  # RKnee to RAnkle

        # å·¦è…¿
        (12, 13): BODY_PART_COLORS['left_leg'],  # LHip to LKnee
        (13, 14): BODY_PART_COLORS['left_leg']  # LKnee to LAnkle
    }

    if show_legend:
        legend_fig = plt.figure(figsize=(width / 100, 1))
        legend_ax = legend_fig.add_subplot(111)
        legend_elements = [
            Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10, label=name)
            for name, color in BODY_PART_COLORS.items()
        ]
        legend_ax.legend(handles=legend_elements, loc='center', ncol=len(BODY_PART_COLORS), title="Body Parts")
        legend_ax.axis('off')

        canvas = FigureCanvas(legend_fig)
        canvas.draw()
        legend_arr = np.array(canvas.renderer.buffer_rgba())
        legend_arr = cv2.cvtColor(legend_arr, cv2.COLOR_RGBA2BGR)
        legend_height = legend_arr.shape[0]
        plt.close(legend_fig)
    else:
        legend_arr = None
        legend_height = 0

    total_height = height + legend_height
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(output_file, fourcc, fps, (width, total_height))

    print(f"å¼€å§‹ç”Ÿæˆè§†é¢‘: {output_file}ï¼Œå…± {frames} å¸§")

    with tqdm(total=frames, desc="ç”Ÿæˆè§†é¢‘", unit="å¸§") as pbar:
        for frame_idx in range(frames):
            frame_img = np.ones((total_height, width, 3), dtype=np.uint8) * 255

            fig, ax = plt.subplots(figsize=(width / 100, height / 100), dpi=100)

            keypoints = reshaped_keypoints[frame_idx]

            for connection in SKELETON_CONNECTIONS:
                start_idx, end_idx = connection
                color = CONNECTION_COLORS.get(connection, 'gray')
                ax.plot([keypoints[start_idx, 0], keypoints[end_idx, 0]],
                        [keypoints[start_idx, 1], keypoints[end_idx, 1]],
                        color=color, linewidth=3)

            for part_name, indices in KEYPOINT_GROUPS.items():
                color = BODY_PART_COLORS[part_name]
                part_keypoints = keypoints[indices]
                ax.scatter(part_keypoints[:, 0], part_keypoints[:, 1],
                           c=color, s=50, edgecolors='black')

            if show_labels:
                for i, (x, y) in enumerate(keypoints):
                    ax.text(x, y, str(i), fontsize=10, ha='center', va='center', color='white',
                            bbox=dict(boxstyle="circle,pad=0.1", fc='black', ec='none', alpha=0.7))

            ax.set_xlim(x_min - x_margin, x_max + x_margin)
            ax.set_ylim(y_max + y_margin, y_min - y_margin)
            ax.set_title(f"Pose - Frame {frame_idx + 1}/{frames}", fontsize=14)
            ax.set_aspect('equal')
            ax.axis('off')

            plt.tight_layout()

            canvas = FigureCanvas(fig)
            canvas.draw()
            mat_img = np.array(canvas.renderer.buffer_rgba())
            mat_img = cv2.cvtColor(mat_img, cv2.COLOR_RGBA2BGR)

            h, w = mat_img.shape[:2]
            frame_img[:h, :w] = mat_img

            if show_legend and legend_arr is not None:
                lh, lw = legend_arr.shape[:2]
                y_offset = h
                frame_img[y_offset:y_offset + lh, :lw] = legend_arr

            video_writer.write(frame_img)
            plt.close(fig)
            pbar.update(1)

    video_writer.release()
    print(f"è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_file}")
    return output_file


def create_side_by_side_video_opencv(true_keypoints, pred_keypoints, output_file="comparison.mp4",
                                     keypoint_scale=1.0, fps=30):
    """åˆ›å»ºå¯¹æ¯”è§†é¢‘"""
    import cv2
    import numpy as np
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas
    from tqdm import tqdm

    frames = min(len(true_keypoints), len(pred_keypoints))
    true_reshaped = true_keypoints[:frames].reshape(frames, -1, 2)
    pred_reshaped = pred_keypoints[:frames].reshape(frames, -1, 2)

    if keypoint_scale != 1.0:
        true_reshaped *= keypoint_scale
        pred_reshaped *= keypoint_scale

    # è®¡ç®—å…¨å±€èŒƒå›´
    all_x = np.concatenate([true_reshaped[:, :, 0].flatten(), pred_reshaped[:, :, 0].flatten()])
    all_y = np.concatenate([true_reshaped[:, :, 1].flatten(), pred_reshaped[:, :, 1].flatten()])

    x_min, x_max = np.min(all_x), np.max(all_x)
    y_min, y_max = np.min(all_y), np.max(all_y)

    margin = 0.1
    x_margin = (x_max - x_min) * margin
    y_margin = (y_max - y_min) * margin

    # éª¨éª¼è¿æ¥å’Œé¢œè‰²
    SKELETON_CONNECTIONS = [
        (0, 1), (1, 8),
        (1, 2), (2, 3), (3, 4),
        (1, 5), (5, 6), (6, 7),
        (8, 9), (8, 12),
        (9, 10), (10, 11),
        (12, 13), (13, 14)
    ]

    BODY_PART_COLORS = {
        'head': 'magenta',
        'torso': 'red',
        'right_arm': 'orange',  # å³è‡‚
        'left_arm': 'green',  # å·¦è‡‚
        'right_leg': 'blue',  # å³è…¿
        'left_leg': 'cyan'  # å·¦è…¿
    }

    KEYPOINT_GROUPS = {
        'head': [0],
        'torso': [1, 8],
        'left_arm': [2, 3, 4],
        'right_arm': [5, 6, 7],
        'left_leg': [9, 10, 11],
        'right_leg': [12, 13, 14]
    }

    CONNECTION_COLORS = {
        # èº¯å¹²
        (0, 1): BODY_PART_COLORS['torso'],  # Nose to Neck
        (1, 8): BODY_PART_COLORS['torso'],  # Neck to MidHip

        # å³è‡‚ï¼ˆRå¼€å¤´çš„ï¼‰
        (1, 2): BODY_PART_COLORS['right_arm'],  # Neck to RShoulder
        (2, 3): BODY_PART_COLORS['right_arm'],  # RShoulder to RElbow
        (3, 4): BODY_PART_COLORS['right_arm'],  # RElbow to RWrist

        # å·¦è‡‚ï¼ˆLå¼€å¤´çš„ï¼‰
        (1, 5): BODY_PART_COLORS['left_arm'],  # Neck to LShoulder
        (5, 6): BODY_PART_COLORS['left_arm'],  # LShoulder to LElbow
        (6, 7): BODY_PART_COLORS['left_arm'],  # LElbow to LWrist

        # é«‹éƒ¨è¿æ¥
        (8, 9): BODY_PART_COLORS['right_leg'],  # MidHip to RHip
        (8, 12): BODY_PART_COLORS['left_leg'],  # MidHip to LHip

        # å³è…¿
        (9, 10): BODY_PART_COLORS['right_leg'],  # RHip to RKnee
        (10, 11): BODY_PART_COLORS['right_leg'],  # RKnee to RAnkle

        # å·¦è…¿
        (12, 13): BODY_PART_COLORS['left_leg'],  # LHip to LKnee
        (13, 14): BODY_PART_COLORS['left_leg']  # LKnee to LAnkle
    }

    width, height = 1600, 800
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    video_writer = cv2.VideoWriter(output_file, fourcc, fps, (width, height))

    print(f"å¼€å§‹ç”Ÿæˆå¯¹æ¯”è§†é¢‘: {output_file}ï¼Œå…± {frames} å¸§")

    with tqdm(total=frames, desc="ç”Ÿæˆå¯¹æ¯”è§†é¢‘", unit="å¸§") as pbar:
        for frame_idx in range(frames):
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))

            # çœŸå®å§¿æ€
            true_kp = true_reshaped[frame_idx]
            for connection in SKELETON_CONNECTIONS:
                start_idx, end_idx = connection
                color = CONNECTION_COLORS.get(connection, 'gray')
                ax1.plot([true_kp[start_idx, 0], true_kp[end_idx, 0]],
                         [true_kp[start_idx, 1], true_kp[end_idx, 1]],
                         color=color, linewidth=3)

            for part_name, indices in KEYPOINT_GROUPS.items():
                color = BODY_PART_COLORS[part_name]
                part_keypoints = true_kp[indices]
                ax1.scatter(part_keypoints[:, 0], part_keypoints[:, 1],
                            c=color, s=50, edgecolors='black')

            ax1.set_xlim(x_min - x_margin, x_max + x_margin)
            ax1.set_ylim(y_max + y_margin, y_min - y_margin)
            ax1.set_title(f"True Pose - Frame {frame_idx + 1}", fontsize=14)
            ax1.set_aspect('equal')
            ax1.axis('off')

            # é¢„æµ‹å§¿æ€
            pred_kp = pred_reshaped[frame_idx]
            for connection in SKELETON_CONNECTIONS:
                start_idx, end_idx = connection
                color = CONNECTION_COLORS.get(connection, 'gray')
                ax2.plot([pred_kp[start_idx, 0], pred_kp[end_idx, 0]],
                         [pred_kp[start_idx, 1], pred_kp[end_idx, 1]],
                         color=color, linewidth=3)

            for part_name, indices in KEYPOINT_GROUPS.items():
                color = BODY_PART_COLORS[part_name]
                part_keypoints = pred_kp[indices]
                ax2.scatter(part_keypoints[:, 0], part_keypoints[:, 1],
                            c=color, s=50, edgecolors='black')

            ax2.set_xlim(x_min - x_margin, x_max + x_margin)
            ax2.set_ylim(y_max + y_margin, y_min - y_margin)
            ax2.set_title(f"Predicted Pose - Frame {frame_idx + 1}", fontsize=14)
            ax2.set_aspect('equal')
            ax2.axis('off')

            plt.tight_layout()

            canvas = FigureCanvas(fig)
            canvas.draw()
            mat_img = np.array(canvas.renderer.buffer_rgba())
            mat_img = cv2.cvtColor(mat_img, cv2.COLOR_RGBA2BGR)

            video_writer.write(mat_img)
            plt.close(fig)
            pbar.update(1)

    video_writer.release()
    print(f"å¯¹æ¯”è§†é¢‘ç”Ÿæˆå®Œæˆ: {output_file}")
    return output_file

# ============================== #
# ä¸»è®­ç»ƒå‡½æ•°ï¼ˆä½¿ç”¨PAMæ ¼å¼ï¼‰
# ============================== #
def train_wisppn_pam_model(train_loader, val_loader, test_loader,
                           batch_size=32, num_epochs=20, learning_rate=0.001,
                           keypoint_scale=1000.0, output_dir="wisppn_pam_results"):
    """è®­ç»ƒä½¿ç”¨PAMæ ¼å¼æ ‡ç­¾çš„WISPPNæ¨¡å‹ï¼ˆä¸åŸå§‹ä»£ç ä¿æŒä¸€è‡´ï¼‰"""
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

    # åˆå§‹åŒ–æ¨¡å‹
    print("åˆå§‹åŒ–WISPPNæ¨¡å‹ï¼ˆPAMç‰ˆæœ¬ï¼‰...")
    wisppn = ResNet(ResidualBlock, [2, 2, 2, 2], input_channels=600)
    wisppn = wisppn.cuda()

    # ========== æç®€æ¨¡å‹ç»Ÿè®¡ï¼ˆåªè¦è¿™å‡ è¡Œï¼‰ ==========
    # 1. è®¡ç®—æ€»å‚æ•°é‡
    total_params = sum(p.numel() for p in wisppn.parameters() if p.requires_grad)
    print(f"\nğŸ“Š æ¨¡å‹æ€»å‚æ•°é‡: {total_params:,} ({total_params / 1e6:.2f}M)")

    # 2. è®¡ç®—FLOPs
    try:
        from thop import profile
        import copy

        # åˆ›å»ºæ­£ç¡®å¤§å°çš„æµ‹è¯•è¾“å…¥
        model_copy = copy.deepcopy(wisppn)
        model_copy.eval()

        # æ³¨æ„ï¼šè¾“å…¥åº”è¯¥æ˜¯è½¬æ¢åçš„æ ¼å¼ [1, 600, 3, 6]
        test_input = torch.randn(1, 600, 3, 6).to(device)

        with torch.no_grad():
            flops, params = profile(model_copy, inputs=(test_input,), verbose=False)
        print(f"ğŸ’» æ¨¡å‹è®¡ç®—é‡: {flops / 1e6:.2f}M FLOPs")
        print(f"ğŸ“Š THOPå‚æ•°é‡: {params:,} ({params / 1e6:.2f}M)")

        del model_copy, test_input

    except ImportError:
        print("ğŸ’» FLOPsè®¡ç®—éœ€è¦å®‰è£…: pip install thop")
    except Exception as e:
        print(f"ğŸ’» FLOPsè®¡ç®—å‡ºé”™: {e}")
        print("ğŸ’» è·³è¿‡FLOPsè®¡ç®—ï¼Œç»§ç»­è®­ç»ƒ...")

    # æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion_L2 = nn.MSELoss().cuda()
    optimizer = torch.optim.Adam(wisppn.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10, 15, 20, 25, 30], gamma=0.5)

    # è®­ç»ƒå†å²è®°å½•ï¼ˆåªè®°å½•è®­ç»ƒæŸå¤±ï¼‰
    train_losses = []

    # ============================== #
    # è®­ç»ƒå¾ªç¯ï¼ˆä¸åŸå§‹ä»£ç ä¸€è‡´ï¼Œæ— éªŒè¯ï¼‰
    # ============================== #
    print("å¼€å§‹è®­ç»ƒï¼ˆä½¿ç”¨PAMæ ‡ç­¾ï¼‰...")
    wisppn.train()

    for epoch_index in range(num_epochs):
        start = time.time()

        # æ‰“ä¹±æ•°æ®ï¼ˆåŸå§‹ä»£ç ä¸­çš„shuffle(mats)ï¼‰
        # DataLoaderå·²ç»è®¾ç½®äº†shuffle=Trueï¼Œæ‰€ä»¥è¿™é‡Œä¸éœ€è¦é¢å¤–æ“ä½œ

        epoch_losses = []

        # è®­ç»ƒæ‰¹æ¬¡å¾ªç¯
        train_loop = tqdm(train_loader, desc=f"Epoch {epoch_index + 1}/{num_epochs}")

        for batch_index, (csi_batch, pam_batch) in enumerate(train_loop):
            # è½¬æ¢CSIæ ¼å¼
            csi_data = convert_csi_format(csi_batch).cuda()

            # PAMæ ‡ç­¾å¤„ç†ï¼ˆä¸åŸå§‹ä»£ç ä¸€è‡´ï¼‰
            xy = pam_batch[:, 0:2, :, :].cuda()  # x'å’Œy'é€šé“
            confidence = pam_batch[:, 2:4, :, :].cuda()  # ç½®ä¿¡åº¦é€šé“ï¼ˆåŸå§‹ä»£ç ç”¨2ä¸ªé€šé“ï¼‰

            # å¦‚æœåªæœ‰3ä¸ªé€šé“ï¼Œå¤åˆ¶ç½®ä¿¡åº¦é€šé“
            if pam_batch.shape[1] == 3:
                confidence = pam_batch[:, 2:3, :, :].cuda()
                confidence = confidence.repeat(1, 2, 1, 1)  # æ‰©å±•ä¸º2ä¸ªé€šé“

            # å‰å‘ä¼ æ’­
            pred_xy = wisppn(csi_data)

            # è®¡ç®—æŸå¤±ï¼ˆä¸åŸå§‹ä»£ç å®Œå…¨ä¸€è‡´ï¼‰
            loss = criterion_L2(torch.mul(confidence, pred_xy), torch.mul(confidence, xy))

            # æ‰“å°æŸå¤±ï¼ˆåŸå§‹ä»£ç çš„print(loss.item())ï¼‰
            if batch_index % 10 == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡
                print(f"Batch {batch_index}: {loss.item():.6f}")

            # è®°å½•æŸå¤±
            epoch_losses.append(loss.item())

            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # æ›´æ–°è¿›åº¦æ¡
            train_loop.set_postfix(loss=loss.item())

        # è®¡ç®—epochå¹³å‡æŸå¤±
        avg_epoch_loss = np.mean(epoch_losses)
        train_losses.append(avg_epoch_loss)

        endl = time.time()
        print(f'Epoch {epoch_index + 1}: Avg Loss: {avg_epoch_loss:.6f}, '
              f'Costing time: {(endl - start) / 60:.2f} minutes')

        scheduler.step()  # ç§»åˆ°è¿™é‡Œ

    # ä¿å­˜æ¨¡å‹ï¼ˆä¸åŸå§‹ä»£ç ä¸€è‡´ï¼‰
    os.makedirs('weights', exist_ok=True)
    model_path = f'weights/wisppn-{num_epochs}epochs.pkl'
    torch.save(wisppn, model_path)
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")

    # ============================== #
    # æµ‹è¯•é˜¶æ®µï¼ˆç±»ä¼¼åŸå§‹ä»£ç ï¼Œä½†æ·»åŠ è¯„ä¼°æŒ‡æ ‡ï¼‰
    # ============================== #
    print("\nå¼€å§‹æµ‹è¯•...")
    wisppn = wisppn.cuda().eval()

    # ç”¨äºä¿å­˜æ‰€æœ‰é¢„æµ‹å’ŒçœŸå®åæ ‡
    all_pred_coords = []
    all_true_coords = []

    # è¯„ä¼°æŒ‡æ ‡ï¼ˆé¢å¤–æ·»åŠ çš„ï¼ŒåŸå§‹ä»£ç æ²¡æœ‰ï¼‰
    test_mpes = []
    test_pcks = {0.1: [], 0.2: [], 0.3: [], 0.4: [], 0.5: []}

    with torch.no_grad():
        test_loop = tqdm(test_loader, desc="Testing")

        for batch_idx, (csi_batch, pam_batch) in enumerate(test_loop):
            # è½¬æ¢CSIæ ¼å¼
            csi_data = convert_csi_format(csi_batch).cuda()

            # å‰å‘ä¼ æ’­
            pred_xy = wisppn(csi_data)  # è¾“å‡º [batch_size, 2, 15, 15]

            # ä»PAMå¯¹è§’çº¿æå–å…³é”®ç‚¹åæ ‡ï¼ˆä¸åŸå§‹æµ‹è¯•ä»£ç ä¸€è‡´ï¼‰
            batch_size = pred_xy.shape[0]
            pred_keypoints = torch.zeros(batch_size, 15, 2).cuda()
            true_keypoints = torch.zeros(batch_size, 15, 2).cuda()

            for b in range(batch_size):
                for index in range(15):
                    # ä»é¢„æµ‹PAMæå–åæ ‡
                    pred_keypoints[b, index, 0] = pred_xy[b, 0, index, index]  # xåæ ‡
                    pred_keypoints[b, index, 1] = pred_xy[b, 1, index, index]  # yåæ ‡

                    # ä»çœŸå®PAMæå–åæ ‡
                    true_keypoints[b, index, 0] = pam_batch[b, 0, index, index].cuda()
                    true_keypoints[b, index, 1] = pam_batch[b, 1, index, index].cuda()

            # ä¿å­˜åæ ‡ç”¨äºè§†é¢‘ç”Ÿæˆ
            all_pred_coords.extend(pred_keypoints.cpu().numpy())
            all_true_coords.extend(true_keypoints.cpu().numpy())

            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆé¢å¤–æ·»åŠ çš„åŠŸèƒ½ï¼‰
            mpe = mean_keypoint_error(pred_keypoints, true_keypoints, keypoint_scale)
            test_mpes.append(mpe)

            pck_results = calculate_pck_metrics(pred_keypoints, true_keypoints,
                                                thresholds=[0.1, 0.2, 0.3, 0.4, 0.5])
            for threshold, value in pck_results.items():
                test_pcks[threshold].append(value)

            # æ›´æ–°è¿›åº¦æ¡
            test_loop.set_postfix(mpe=mpe, pck20=pck_results[0.2])

            # å¯é€‰ï¼šæ˜¾ç¤ºç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„é¢„æµ‹ï¼ˆç±»ä¼¼åŸå§‹ä»£ç çš„å¯è§†åŒ–ï¼‰
            if batch_idx == 0:
                print(f"\nç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„é¢„æµ‹ç¤ºä¾‹:")
                print(f"  é¢„æµ‹åæ ‡èŒƒå›´ - X: [{pred_keypoints[0, :, 0].min():.2f}, "
                      f"{pred_keypoints[0, :, 0].max():.2f}]")
                print(f"  é¢„æµ‹åæ ‡èŒƒå›´ - Y: [{pred_keypoints[0, :, 1].min():.2f}, "
                      f"{pred_keypoints[0, :, 1].max():.2f}]")

    # è®¡ç®—å¹³å‡è¯„ä¼°æŒ‡æ ‡
    avg_test_mpe = np.mean(test_mpes) if test_mpes else float('inf')
    avg_test_pcks = {k: np.mean(v) if v else 0.0 for k, v in test_pcks.items()}

    print(f"\nğŸ¯ æµ‹è¯•ç»“æœ:")
    print(f"   MPE: {avg_test_mpe:.4f}")
    print(f"   PCK@0.1: {avg_test_pcks[0.1]:.4f}")
    print(f"   PCK@0.2: {avg_test_pcks[0.2]:.4f}")
    print(f"   PCK@0.3: {avg_test_pcks[0.3]:.4f}")
    print(f"   PCK@0.4: {avg_test_pcks[0.4]:.4f}")
    print(f"   PCK@0.5: {avg_test_pcks[0.5]:.4f}")

    # ============================== #
    # ç”Ÿæˆå¯è§†åŒ–è§†é¢‘
    # ============================== #
    if all_pred_coords and all_true_coords:
        print("\nç”Ÿæˆå§¿æ€è§†é¢‘...")

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        all_pred_coords_np = np.array(all_pred_coords)
        all_true_coords_np = np.array(all_true_coords)

        # é™åˆ¶è§†é¢‘é•¿åº¦
        max_frames = min(720, len(all_pred_coords_np))

        videos_dir = os.path.join(output_dir, "videos")
        os.makedirs(videos_dir, exist_ok=True)

        print(f"ç”Ÿæˆå‰{max_frames}å¸§çš„è§†é¢‘...")

        try:
            # ç”ŸæˆçœŸå®å§¿æ€è§†é¢‘
            true_video = create_pose_animation_opencv(
                all_true_coords_np[:max_frames],
                output_file=os.path.join(videos_dir, "true_poses.mp4"),
                keypoint_scale=keypoint_scale,
                show_labels=False
            )

            # ç”Ÿæˆé¢„æµ‹å§¿æ€è§†é¢‘
            pred_video = create_pose_animation_opencv(
                all_pred_coords_np[:max_frames],
                output_file=os.path.join(videos_dir, "predicted_poses.mp4"),
                keypoint_scale=keypoint_scale,
                show_labels=False
            )

            # ç”Ÿæˆå¯¹æ¯”è§†é¢‘
            comparison_video = create_side_by_side_video_opencv(
                all_true_coords_np[:max_frames],
                all_pred_coords_np[:max_frames],
                output_file=os.path.join(videos_dir, "comparison.mp4"),
                keypoint_scale=keypoint_scale,
                fps=30
            )

            print(f"\nè§†é¢‘ç”Ÿæˆå®Œæˆ!")
            print(f"  çœŸå®å§¿æ€è§†é¢‘: {true_video}")
            print(f"  é¢„æµ‹å§¿æ€è§†é¢‘: {pred_video}")
            print(f"  å¯¹æ¯”è§†é¢‘: {comparison_video}")

        except Exception as e:
            print(f"ç”Ÿæˆè§†é¢‘æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    # ============================== #
    # ä¿å­˜ç»“æœ
    # ============================== #
    os.makedirs(output_dir, exist_ok=True)

    # ä¿å­˜æµ‹è¯•ç»“æœ
    test_results = {
        'MPE': avg_test_mpe,
        'PCK@0.1': avg_test_pcks[0.1],
        'PCK@0.2': avg_test_pcks[0.2],
        'PCK@0.3': avg_test_pcks[0.3],
        'PCK@0.4': avg_test_pcks[0.4],
        'PCK@0.5': avg_test_pcks[0.5]
    }

    import pandas as pd
    results_df = pd.DataFrame([test_results])
    results_df.to_csv(os.path.join(output_dir, 'test_results.csv'), index=False)

    # ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, 'b-', label='Training Loss')
    plt.title('Training Loss Curve')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(os.path.join(output_dir, 'training_loss.png'))
    plt.show()

    print(f"\næ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ°: {output_dir}")

    return wisppn, test_results


def main():
    # è®­ç»ƒå‚æ•°
    batch_size = 32
    num_epochs = 20
    learning_rate = 0.001

    # æ•°æ®ç›®å½•
    csi_data_dir = "preprocessed_csi_data"  # CSIé¢„å¤„ç†æ•°æ®
    pam_label_dir = "keypoints_pam_data"  # PAMæ ¼å¼æ ‡ç­¾ç›®å½•

    # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨
    if not os.path.exists(csi_data_dir) or not os.path.exists(os.path.join(csi_data_dir, "csi_windows.npy")):
        print(f"é”™è¯¯: æœªæ‰¾åˆ°CSIé¢„å¤„ç†æ•°æ® {csi_data_dir}")
        return

    if not os.path.exists(pam_label_dir):
        print(f"é”™è¯¯: æœªæ‰¾åˆ°PAMæ ‡ç­¾ç›®å½• {pam_label_dir}")
        return

    # åˆ›å»ºæ•°æ®é›†
    print("æ­£åœ¨åŠ è½½æ•°æ®...")
    full_dataset = PreprocessedCSIKeypointsDataset(
        csi_data_dir=csi_data_dir,
        pam_label_dir=pam_label_dir,
        keypoint_scale=1000.0,  # æ·»åŠ è¿™ä¸€è¡Œ
        enable_zero_clean=True  # å¯ç”¨é›¶å€¼æ¸…ç†
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = create_train_val_test_loaders(
        dataset=full_dataset,
        batch_size=batch_size,
        num_workers=0
    )

    # æµ‹è¯•æ•°æ®åŠ è½½
    print("\næµ‹è¯•æ•°æ®åŠ è½½...")
    for csi_batch, pam_batch in train_loader:
        print(f"CSIæ•°æ®å½¢çŠ¶: {csi_batch.shape}")  # [batch_size, 540, 20]
        print(f"PAMæ ‡ç­¾å½¢çŠ¶: {pam_batch.shape}")  # [batch_size, 4, 15, 15]
        print(f"  - x'é€šé“å½¢çŠ¶: {pam_batch[:, 0, :, :].shape}")
        print(f"  - y'é€šé“å½¢çŠ¶: {pam_batch[:, 1, :, :].shape}")
        print(f"  - c'é€šé“å½¢çŠ¶: {pam_batch[:, 2, :, :].shape}")
        break

    # è®­ç»ƒæ¨¡å‹
    model, test_results = train_wisppn_pam_model(
        train_loader, val_loader, test_loader,
        batch_size=batch_size,
        num_epochs=num_epochs,
        learning_rate=learning_rate,
        keypoint_scale=1000.0,
        output_dir="wisppn_pam_results3"
    )

    print("\nè®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()